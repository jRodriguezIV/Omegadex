{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7865b466",
   "metadata": {},
   "source": [
    "# **Cost Optimization Tools** #\n",
    "One of the most important considerations when using cloud-based systems is cost optimization, which is the reduction of cost with the maximum business value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1795dc",
   "metadata": {},
   "source": [
    "## **Customer example** ##\n",
    "\n",
    "A successful medical imaging services company was running into problems. They had a large and growing backlog of medical images such as X-rays, MRIs, and CT scans that needed to be analyzed. Their radiologists were overloaded, and they had a high turnover rate.\n",
    "\n",
    "They began experimenting with some AI-based image analysis software, but they experienced challenges. The volume and variety of image formats was overwhelming, and their system did not have the necessary computational requirements.\n",
    "\n",
    "The company had been using cloud storage for some of their images, but they decided to go all-in on a cloud-based analytics system. After some successful test runs, they migrated their workloads to the AWS Cloud. The results were astounding. The backlog disappeared, their business grew, and most importantly, the doctors and patients were happy.\n",
    "\n",
    "But soon they were seeing significant cost overruns. \n",
    "\n",
    "What went wrong?\n",
    "\n",
    "### Although their new system worked, they had tested and deployed it without a proper consideration of cost optimization. ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac4141",
   "metadata": {},
   "source": [
    "## **Challenges of cost optimization** ##\n",
    "\n",
    "Optimizing costs in data analytics systems can be challenging because of several factors. The following are some of the biggest challenges.\n",
    "\n",
    "**Data volume and variety**\n",
    "As the volume and variety of data grow, the cost of storage, processing, and analysis can increase significantly.\n",
    "\n",
    "**Scalability requirements**\n",
    "Data analytics systems often need to scale up or down based on demand, and this can lead to fluctuating costs.\n",
    "\n",
    "**Underutilized resources**\n",
    "Data analytics resources, such as compute instances, storage, or databases, are often underutilized, which can lead to unnecessary costs.\n",
    "\n",
    "**Complexity of analytics workloads**\n",
    "Advanced analytics workloads, such as machine learning, deep learning, or real-time streaming analytics, can be computationally expensive and require specialized hardware or services. These specialized services increase costs.\n",
    "\n",
    "**Data movement and transfer costs**\n",
    "Moving or transferring large volumes of data between different storage locations or services can incur significant costs. This is especially true if data needs to be transferred across Regions, among cloud providers, or with on-premises systems.\n",
    "\n",
    "**Lack of cost monitoring and governance**\n",
    "Without proper cost monitoring, reporting, and governance mechanisms, it can be challenging to identify cost optimization opportunities and enforce cost-saving measures.\n",
    "\n",
    "**Skills and expertise**\n",
    "Optimizing costs in data analytics systems often requires specialized skills and expertise in areas such as cloud computing, data engineering, and cost management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f5e91",
   "metadata": {},
   "source": [
    "## **Cost optimization options** ##\n",
    "\n",
    "AWS offers a combination of strategies and options that can greatly optimize costs while maintaining the required performance and reliability levels. Not all of these features will apply to all services, but many of the following tools and strategies can be used to reduce costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92efee17",
   "metadata": {},
   "source": [
    "**Cost optimization in architecture**\n",
    "\n",
    "•\n",
    "**Serverless computing:** You can run your data analytics code using services such as Lambda, Amazon Redshift Serverless, and Amazon EMR Serverless without provisioning or managing servers. You pay only for the compute time consumed, which makes it a cost-effective option for event-driven or sporadic workloads.\n",
    "\n",
    "•\n",
    "**Auto scaling:** Auto scaling helps optimize costs by automatically scaling compute resources up or down based on demand. This is particularly powerful with data processing or analytics clusters because it ensures that you have sufficient resources during peak loads and scaling down during idle periods to save costs.\n",
    "\n",
    "•\n",
    "**Data lifecycle management:** By implementing data lifecycle management strategies, you can optimize storage costs. This includes archiving or deleting old or unused data, compressing data, or moving infrequently accessed data to cheaper storage tiers like object storage or cold storage.\n",
    "\n",
    "•\n",
    "**Query optimization:** By optimizing your data analytics queries, you can reduce compute costs by minimizing unnecessary operations or data transfers. This might involve techniques like indexing, query rewriting, partitioning, or caching frequently accessed data.\n",
    "\n",
    "•\n",
    "**Resource monitoring and rightsizing:** Continuously monitoring your resource use and rightsizing your instances can help ensure you're not over-provisioning or under-provisioning resources. You can identify and scale down underutilized resources or scale up resources that are consistently overloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e285df9d",
   "metadata": {},
   "source": [
    "## **Cost-optimized pricing structures** ##\n",
    "\n",
    " **Reserved Instances**\n",
    "You can purchase Reserved Instances (RI) for a specific instance type, platform, and availability zone for a 1-year or 3-year term. By committing to this long-term usage, you can save up to 72 percent compared to On-Demand Instance pricing. This is very effective for predictable and long-term resource requirements such as web servers, application servers, or databases.\n",
    "\n",
    "**Spot Instances**\n",
    "Spot Instances are spare Amazon EC2 computing capacity offered at significantly discounted prices compared to On-Demand Instance pricing. The prices fluctuate based on supply and demand, but you can set a maximum price you're willing to pay. These instances can be used for batch processing jobs or non-critical workloads that can tolerate interruptions such as data preprocessing, model training, or batch analytics jobs.\n",
    "\n",
    "**Savings Plans**\n",
    "Savings Plans are a flexible pricing model that provides discounts based on a long-term usage commitment (1-year or 3-year term). Unlike RI, Savings Plans apply to future usage across EC2 instance families (such as M, C, R) in a Region or a combination of Regions. They offer savings of up to 72 percent compared to On-Demand Instance pricing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cac980",
   "metadata": {},
   "source": [
    "## **AWS services for cost optimization** ##\n",
    "\n",
    "AWS provides several services that can help optimize costs in data analytics systems. The following are some key AWS services that can be used for cost optimization.\n",
    "\n",
    "\n",
    "**AWS Cost Explorer**\n",
    "This service provides visibility into your AWS costs and usage patterns. You can use it to analyze and identify areas for cost savings. It offers features like cost allocation reports, cost forecasting, and anomaly detection.\n",
    "\n",
    "**AWS Budgets**\n",
    "With AWS Budgets, you can set custom budgets and receive alerts when your costs or usage exceed (or are forecasted to exceed) the budgeted amount. This helps you proactively manage costs and avoid unexpected expenses.\n",
    "\n",
    "\n",
    "\n",
    "**AWS data transfer pricing tier**\n",
    "AWS offers a data transfer pricing tier that can significantly reduce costs for large-scale data transfers within the same AWS Region or between different Regions.\n",
    "\n",
    "**Amazon S3 Intelligent-Tiering**\n",
    "This storage class for Amazon S3 automatically moves objects to the most cost-effective access tier based on changing access patterns. This helps optimize storage costs.\n",
    "\n",
    "\n",
    "\n",
    "**AWS Auto Scaling**\n",
    "By using AWS Auto Scaling for your data analytics resources (such as EC2 instances and EMR clusters), you can automatically scale resources up or down based on demand. This ensures that you only pay for the resources you need.\n",
    "\n",
    "**AWS Cost Anomaly Detection**\n",
    "This machine learning-powered feature can automatically detect anomalies in your AWS cost and usage data, helping you identify and address potential cost spikes or inefficiencies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3575f8",
   "metadata": {},
   "source": [
    "## **Customer example** ##\n",
    "\n",
    "The medical image services company used AWS Cost Explorer and AWS Budgets to get control of their system costs. Based on the insights gained from AWS Cost Explorer and the control provided by AWS Budgets, the company implemented the following cost optimization strategies.\n",
    "\n",
    "\n",
    "### **Cost Explorer** ###\n",
    "Using Cost Explorer, the company's data engineering team was able to do the following:\n",
    "\n",
    "- **Analyze cost breakdown by service:** The team used Cost Explorer to break down their costs by individual AWS services. They discovered that a significant portion of their costs was attributed to their EMR clusters, which were running continuously, even during periods of low utilization.\n",
    "- **Identify cost spikes and anomalies:** By setting up cost anomaly detection in Cost Explorer, the team was alerted to unexpected cost spikes during certain periods. Upon investigation, they found that these spikes were caused by a misconfigured Redshift cluster that was provisioned with more resources than necessary.\n",
    "- **Forecast future costs:** Using the Cost Explorer forecasting capabilities, the team was able to project their future costs based on their current usage patterns. This helped them plan and budget for upcoming data analytics initiatives more effectively.\n",
    "- **Implement cost allocation tags:** The team implemented cost allocation tags to track costs by different departments, projects, or workloads. They identified which business units or initiatives were driving the highest costs and prioritized cost optimization efforts accordingly.\n",
    "\n",
    "### **AWS Budget** ###\n",
    "To complement the insights from Cost Explorer, the company also set up AWS Budgets:\n",
    "\n",
    "- **Cost budgets by service:** They created cost budgets for their major AWS services used in the data analytics system, such as Amazon EMR, Amazon Redshift, and Lambda. These budgets helped them monitor and control costs for each service.\n",
    "- **Project-level cost budgets:** They set up cost budgets for different data analytics projects or initiatives. As a result, the project managers could track and stay within their allocated budgets.\n",
    "- **Budget alerts and notifications:** They configured budget alerts and notifications to be sent to relevant stakeholders (such as project managers, data engineers, and the finance team) when actual or forecasted costs reached specific thresholds.\n",
    "\n",
    "\n",
    "### **Strategies** ###\n",
    "Based on the insights gained from Cost Explorer and the control provided by AWS Budgets, the company implemented the following cost optimization strategies:\n",
    "\n",
    "- **Rightsizing EMR clusters:** They configured their EMR clusters to automatically terminate after job completion. This reduced idle time and associated costs.\n",
    "- **Optimizing Redshift configuration:** They rightsized their Redshift cluster to match their actual workload requirements. This reduced unnecessary provisioned capacity and associated costs.\n",
    "- **Using Spot Instances:** For certain non-critical workloads, they started using Spot Instances. Spot Instances can offer significant cost savings compared to On-Demand Instances.\n",
    "- **Enforcing cost governance:** With the help of budget alerts and notifications, they were able to enforce cost governance measures and ensure that project teams stayed within their allocated budgets.\n",
    "\n",
    "By using Cost Explorer, AWS Budgets, and implementing these cost optimization strategies, the medical image services company was able to achieve significant cost savings in their data analytics system and maintain the necessary performance and scalability requirements.\n",
    "\n",
    "\n",
    "## **Summary** ##\n",
    "\n",
    "To avoid excessive and unnecessary costs, it's important to plan for the costs of data volume, complexity, scalability, and data movement. Cost optimization means only paying for what you need and what you actually use. You can use serverless computing, auto scaling, life cycle management of data, query optimization, and resource monitoring to optimize costs. AWS offers specific services for cost optimization. AWS Cost Explorer and AWS Budgets ensure that you're not exceeding any set budgets or paying for resources that are not being used. AWS offers different pricing tiers, intelligent tiering, and auto scaling to ensure you're only paying for resources being used at the correct scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059f8d25",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
